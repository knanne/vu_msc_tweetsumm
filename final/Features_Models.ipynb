{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Tweets\n",
    "\n",
    "## quality\n",
    "Twitter states there is roughly 5% of spam accounts on the site. For event summarization we are not only interested in removing spam content, but also that content which exhibits a number of bad quality traits that would make a summary unclear. Therefore we try to identify the following:\n",
    "* Question\n",
    "* Advertisement\n",
    "* Opinion\n",
    "* Sarcasm\n",
    "* Explicit Language or Graphic Content\n",
    "\n",
    "Much research exists that identifies the above tasks as difficult. Therefore the expectations are our classifiers will not be that great. We take a greedy approach to summarization and accept rouch classification results due to sheer volume of data available.\n",
    "\n",
    "An initial experiment was executed to annotate tweets on wether they contained a question, or language in first person. We analyzed this and found we can classify these tweets using an unsupervised extraction technique with high success rate. Tweets that contain first person pronouns or a question mark are not considered when creating the summary pool.\n",
    "\n",
    "## event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import nltk\n",
    "from nltk import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54162, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data/final/event_indianaprimary_data.txt', sep='\\t', encoding='utf-8', header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated = pd.read_table('data/final/cf_report_905613_Indiana200.csv', sep=',', encoding='utf-8', header=0)\n",
    "df_annotated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge ground truth with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_annotated['question'] = df_annotated['quality'].apply(lambda q: 1 if 'question' in [i for i in str(q).split('\\n')] else 0)\n",
    "#df_annotated['advertisement'] = df_annotated['quality'].apply(lambda q: 1 if 'advertisement' in [i for i in str(q).split('\\n')] else 0)\n",
    "df_annotated['opinion'] = df_annotated['quality'].apply(lambda q: 1 if 'opinion' in [i for i in str(q).split('\\n')] else 0)\n",
    "#df_annotated['sarcasm'] = df_annotated['quality'].apply(lambda q: 1 if 'sarcasm' in [i for i in str(q).split('\\n')] else 0)\n",
    "#df_annotated['content'] = df_annotated['quality'].apply(lambda q: 1 if 'content' in [i for i in str(q).split('\\n')] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['master_id',\n",
    "        #'question',\n",
    "        #'advertisement',\n",
    "        'opinion',\n",
    "        #'sarcasm',\n",
    "        #'content',\n",
    "        'update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_annotated = df_annotated[cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_annotated.columns = ['master_id', \n",
    "    #'y_question',\n",
    "    #'y_advertisement',\n",
    "    'y_opinion',\n",
    "    #'y_sarcasm',\n",
    "    #'y_content',\n",
    "    'y_update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_annotated, on='master_id')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure to handle text as string\n",
    "df['text'] = df['text'].astype('str')\n",
    "#remove links\n",
    "df['text_clean'] = df['text'].apply(lambda text: ' '.join([(w[:w.find('http')] if 'http' in w else w) for w in text.split()]))\n",
    "#remove hashtag symbol\n",
    "df['text_clean'] = df['text_clean'].apply(lambda text: text.replace('#', ''))\n",
    "#remove mention symbol\n",
    "df['text_clean'] = df['text_clean'].apply(lambda text: text.replace('@', ''))\n",
    "#initiate, apply tokenization\n",
    "tknzr = TweetTokenizer()\n",
    "df['text_clean'] = df['text_clean'].apply(lambda s: ' '.join([w.lower() for w in tknzr.tokenize(str(s))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features\n",
    "- some are pulled from existing twitter data\n",
    "- some created\n",
    "    - social\n",
    "        - tweet\n",
    "            - tweet_type\n",
    "            - possibly_sensitive\n",
    "            - is_retweet\n",
    "            - is_reply\n",
    "            - is_quoted_tweet\n",
    "            - favorite_count\n",
    "            - retweet_count\n",
    "            - count_entities_media\n",
    "            - count_entities_urls\n",
    "            - count_entities_mentions\n",
    "            - count_entities_hashtags\n",
    "        - user\n",
    "            - user_default_profile\n",
    "            - user_default_profile_image\n",
    "            - user_verified\n",
    "            - user_statuses\n",
    "            - user_favourites\n",
    "            - user_followers\n",
    "            - user_friends\n",
    "            - user_listed\n",
    "            - user_bio_len\n",
    "            - user_reputation\n",
    "            - user_age_days\n",
    "            - user_follower_rate\n",
    "    - lexical\n",
    "        - count_characters\n",
    "        - count_non_characters\n",
    "        - count_upper\n",
    "        - count_tokens\n",
    "        - count_stops\n",
    "        - question\n",
    "        - elongation\n",
    "        - ellipsis\n",
    "        - lexical_diversity\n",
    "        - sfpp\n",
    "        - pfpp\n",
    "        - pos_cnt\n",
    "        - nes_cnt\n",
    "        - pos_cnt_:\n",
    "        - pos_cnt_DT\n",
    "        - pos_cnt_JJ\n",
    "        - pos_cnt_.\n",
    "        - pos_cnt_EX\n",
    "        - pos_cnt_PRP\n",
    "        - pos_cnt_VBP\n",
    "        - pos_cnt_VBZ\n",
    "        - pos_cnt_,\n",
    "        - pos_cnt_MD\n",
    "        - pos_cnt_``\n",
    "        - pos_cnt_PDT\n",
    "        - pos_cnt_NNP\n",
    "        - pos_cnt_NNS\n",
    "        - pos_cnt_WRB\n",
    "        - pos_cnt_)\n",
    "        - pos_cnt_VB\n",
    "        - pos_cnt_IN\n",
    "        - pos_cnt_NN\n",
    "        - pos_cnt_JJR\n",
    "        - pos_cnt_VBG\n",
    "        - pos_cnt_TO\n",
    "        - pos_cnt_\\$\n",
    "        - pos_cnt_CC\n",
    "        - pos_cnt_UH\n",
    "        - pos_cnt_JJS\n",
    "        - pos_cnt_RP\n",
    "        - pos_cnt_CD\n",
    "        - pos_cnt_PRP\\$\n",
    "        - pos_cnt_RBS\n",
    "        - pos_cnt_SYM\n",
    "        - pos_cnt_(\n",
    "        - pos_cnt_WDT\n",
    "        - pos_cnt_POS\n",
    "        - pos_cnt_VBN\n",
    "        - pos_cnt_WP\n",
    "        - pos_cnt_VBD\n",
    "        - pos_cnt_RB\n",
    "    - semantic\n",
    "        - text_sentiment_polarity\n",
    "        - text_sentiment_subjectivity\n",
    "        - topk_terms_coverage\n",
    "        - tfidf_sum\n",
    "        - tfidf_mean\n",
    "        - event_centroid_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tweet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tweet_type'] = df['tweet_type'].apply(lambda d: [0,1][d=='media']) #1=media, 0=text\n",
    "df['possibly_sensitive'] = df['possibly_sensitive'].apply(lambda d: [0,1][d==True])\n",
    "df['count_entities_media'] = df['entities_media'].apply(lambda media: len(media))\n",
    "df['count_entities_urls'] = df['entities_urls'].apply(lambda urls: len(urls))\n",
    "df['count_entities_mentions'] = df['entities_mentions'].apply(lambda mentions: len(mentions))\n",
    "df['count_entities_hashtags'] = df['entities_hashtags'].apply(lambda tags: len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['user_bio_len'] = df['user_description'].apply(lambda bio: len(str(bio)))\n",
    "df['user_verified'] = df['user_verified'].apply(lambda d: [0,1][d==True])\n",
    "df['user_default_profile'] = df['user_default_profile'].apply(lambda d: [0,1][d==True])\n",
    "df['user_default_profile_image'] = df['user_default_profile_image'].apply(lambda d: [0,1][d==True])\n",
    "df['user_reputation'] = df['user_followers'] / (df['user_friends'])\n",
    "df['user_reputation'].replace(np.inf, np.nan, inplace=True)\n",
    "df['user_age_days'] = df['user_created_at'].apply(lambda created_at: (datetime.today() - pd.to_datetime(created_at)).days)\n",
    "df['user_follower_rate'] = df['user_followers'] / df['user_age_days']\n",
    "df['user_follower_rate'].replace(np.inf, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tweet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['count_characters'] = df['text'].apply(lambda text: len(str(text)))\n",
    "df['count_non_characters'] = df['text'].apply(lambda text: len(re.sub('[\\w+!@#$%&;:,.?\\/\\-“”’`\"\\'()|]', '', text).strip()))\n",
    "df['count_upper'] = df['text'].apply(lambda text: len([l for l in ' '.join([w for w in text.split() if not w.startswith(('#', '@'))]) if l.isupper()]))\n",
    "df['count_tokens'] = df['text_clean'].apply(lambda text: len([w for w in text.split()]))\n",
    "#create stop word list\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "df['count_stops'] = df['text_clean'].head().apply(lambda text: len([t for t in text.split() if t in stop]))\n",
    "df['question'] = df['text_clean'].apply(lambda text: 1 if '?' in text else 0)\n",
    "#create elongation regular expression match\n",
    "elongated = re.compile('([a-zA-Z])\\\\1{3,}')\n",
    "df['elongation'] = df['text_clean'].apply(lambda text: 1 if bool(elongated.search(text)) else 0)\n",
    "df['ellipsis'] = df['text_clean'].apply(lambda text: 1 if any(x in text for x in ('...', '…')) else 0)\n",
    "df['lexical_diversity'] = df['text_clean'].apply(lambda text: len(set(text.split())) / len(text.split()))\n",
    "# singular first person pronoun\n",
    "sfpp = ['i', 'i\\'m', 'me', 'mine', 'my', 'myself']\n",
    "df['sfpp'] = df['text_clean'].apply(lambda text: 1 if any(t.lower() in sfpp for t in text.split()) else 0)\n",
    "# plural first person pronoun\n",
    "pfpp = ['we', 'we\\'re', 'ours', 'our', 'ourselves']\n",
    "df['pfpp'] = df['text_clean'].apply(lambda text: 1 if any(t.lower() in pfpp for t in text.split()) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### event features (semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text_sentiment_polarity'] = df['text_clean'].apply(lambda text: TextBlob(str(text)).sentiment.polarity)\n",
    "df['text_sentiment_subjectivity'] = df['text_clean'].apply(lambda text: TextBlob(str(text)).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### terms coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get query grams\n",
    "#query_terms = df['query'].unique()\n",
    "#df['query_grams_coverage'] = df['text_clean'].apply(lambda text: len([token for token in text.split() if token.lower() in query_terms]) / len(query_terms))\n",
    "#compress series of tweet texts to list\n",
    "tweets = [ str(d) for d in df[df['is_retweet'] == False]['text_clean']]\n",
    "#extract tokens as list\n",
    "tokens = [ w for t in tweets for w in t.split()]\n",
    "#construct term counter\n",
    "for w in [tokens]:\n",
    "    termcounts = Counter(w)\n",
    "#save top k = 100 most frequent terms\n",
    "topk_terms = termcounts.most_common(100)\n",
    "df['topk_terms_coverage'] = df['text_clean'].apply(lambda text: len([token for token in text.split() if token.lower() in topk_terms]) / len(topk_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use only non retweets for bag of words statistics\n",
    "df_nonrt = df[df['is_retweet'] == False][['master_id', 'text_clean']]\n",
    "#reset index for merging with sparse matrix\n",
    "df_nonrt = df_nonrt.reset_index(drop=True)\n",
    "df_nonrt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize sklearn vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#create matrix of tfidf counts\n",
    "#not considering retweets, due to redundancy skew\n",
    "Xtfidf = tfidf_vectorizer.fit_transform(df_nonrt['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get mean tfidf for each doc\n",
    "Xtfidf_means = Xtfidf.mean(axis=1)\n",
    "df_tfidf_means = pd.DataFrame(Xtfidf_means, columns=['tfidf_mean'])\n",
    "#get sum tfidf for each doc\n",
    "Xtfidf_sums = Xtfidf.sum(axis=1)\n",
    "df_tfidf_sums = pd.DataFrame(Xtfidf_sums, columns=['tfidf_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf_stats = pd.concat([df_tfidf_means, df_tfidf_sums], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add tfidf sum, mean as features\n",
    "df_nonrt = pd.merge(df_nonrt, df_tfidf_stats, how='inner', left_index=True, right_index=True)\n",
    "#join back to full datatset\n",
    "df = pd.merge(df, df_nonrt[['master_id', 'tfidf_sum', 'tfidf_mean']], how='left', on='master_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### event centroid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate event centroid using tfidf mean of all columns (1000 top terms)\n",
    "Xtfidf_centroid = Xtfidf.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute pairwise distance for each doc to centroid using cosine similarity equation\n",
    "Xtfidf_centroid_cosdistance = pairwise_distances(X=Xtfidf, Y=Xtfidf_centroid, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_centroid_distance = pd.DataFrame(Xtfidf_centroid_cosdistance, columns=['event_centroid_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add centroid distance as feature\n",
    "df_nonrt = pd.merge(df_nonrt, df_centroid_distance, how='inner', left_index=True, right_index=True)\n",
    "#join back to full datatset\n",
    "df = pd.merge(df, df_nonrt[['master_id', 'event_centroid_distance']], how='left', on='master_id')\n",
    "#retweet centroid values are set to NaN\n",
    "#because retweets will exempt from modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### parts of speech, named entities\n",
    "- print percent complete\n",
    "- run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0%\n",
      "4.0%\n",
      "6.0%\n",
      "8.0%\n",
      "10.0%\n",
      "12.0%\n",
      "14.0%\n",
      "16.0%\n",
      "18.0%\n",
      "20.0%\n",
      "22.0%\n",
      "24.0%\n",
      "26.0%\n",
      "28.0%\n",
      "30.0%\n",
      "32.0%\n",
      "34.0%\n",
      "36.0%\n",
      "38.0%\n",
      "40.0%\n",
      "42.0%\n",
      "44.0%\n",
      "46.0%\n",
      "48.0%\n",
      "50.0%\n",
      "52.0%\n",
      "54.0%\n",
      "56.0%\n",
      "58.0%\n",
      "60.0%\n",
      "62.0%\n",
      "64.0%\n",
      "66.0%\n",
      "68.0%\n",
      "70.0%\n",
      "72.0%\n",
      "74.0%\n",
      "76.0%\n",
      "78.0%\n",
      "80.0%\n",
      "82.0%\n",
      "84.0%\n",
      "86.0%\n",
      "88.0%\n",
      "90.0%\n",
      "92.0%\n",
      "94.0%\n",
      "96.0%\n",
      "98.0%\n",
      "100.0%\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#classify parts of speech, named entities using nltk classifier\n",
    "#aggregate pos, ne counts, add counts and dictionary of parts/entities to database\n",
    "#this is a slow process, should be redesigned\n",
    "df_nespos = pd.DataFrame()\n",
    "\n",
    "#define function for nltk tree mining\n",
    "def getnes(tree):\n",
    "    ne = []\n",
    "    for node in tree:\n",
    "        if type(node) is nltk.Tree:\n",
    "            label = node.label()\n",
    "            s = ''\n",
    "            for node in node:\n",
    "                s = (s + ' ' + node[0].lower()).lstrip()\n",
    "            ne.append([label, s])\n",
    "    return ne\n",
    "\n",
    "complete_last = 0\n",
    "for i,doc in df.iterrows():\n",
    "    \n",
    "    complete = round((i/df.shape[0])*100)\n",
    "    if complete != complete_last:\n",
    "        if complete % 2 == 0:\n",
    "            print('%s%%' % complete)\n",
    "            complete_last = complete\n",
    "    \n",
    "    tokens = nltk.word_tokenize(str(doc['text_clean']))\n",
    "    \n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    pos_cntr = Counter(list(dict(pos).values()))\n",
    "    pos_data = dict(pos_cntr)\n",
    "    pos_cnt = sum(pos_data.values())\n",
    "    \n",
    "    tree = nltk.ne_chunk(pos)\n",
    "    nes = getnes(tree)\n",
    "    nes_cntr = Counter(list(dict(nes).keys()))\n",
    "    nes_data = dict(nes_cntr)\n",
    "    nes_cnt = sum(nes_data.values())\n",
    "    \n",
    "    row = [pos_cnt, nes_cnt, pos_data, nes_data]\n",
    "    row = pd.Series(row, index=['pos_cnt', 'nes_cnt', 'pos_data', 'nes_data'])\n",
    "    row = pd.DataFrame(row).T\n",
    "    df_nespos = df_nespos.append(row, ignore_index=True)\n",
    "    \n",
    "df = pd.merge(df, df_nespos, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert pos counts to features\n",
    "- print percent complete\n",
    "- run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0%\n",
      "4.0%\n",
      "6.0%\n",
      "8.0%\n",
      "10.0%\n",
      "12.0%\n",
      "14.0%\n",
      "16.0%\n",
      "18.0%\n",
      "20.0%\n",
      "22.0%\n",
      "24.0%\n",
      "26.0%\n",
      "28.0%\n",
      "30.0%\n",
      "32.0%\n",
      "34.0%\n",
      "36.0%\n",
      "38.0%\n",
      "40.0%\n",
      "42.0%\n",
      "44.0%\n",
      "46.0%\n",
      "48.0%\n",
      "50.0%\n",
      "52.0%\n",
      "54.0%\n",
      "56.0%\n",
      "58.0%\n",
      "60.0%\n",
      "62.0%\n",
      "64.0%\n",
      "66.0%\n",
      "68.0%\n",
      "70.0%\n",
      "72.0%\n",
      "74.0%\n",
      "76.0%\n",
      "78.0%\n",
      "80.0%\n",
      "82.0%\n",
      "84.0%\n",
      "86.0%\n",
      "88.0%\n",
      "90.0%\n",
      "92.0%\n",
      "94.0%\n",
      "96.0%\n",
      "98.0%\n",
      "100.0%\n",
      "Wall time: 603 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#get all parts of speach counts, add as features\n",
    "all_pos = []\n",
    "for i,doc in df.iterrows():\n",
    "    all_pos.extend(list(doc['pos_data'].keys()))\n",
    "\n",
    "#get unique pos types\n",
    "all_pos = list(set(all_pos))\n",
    "\n",
    "#create pos feature df\n",
    "df_pos = pd.DataFrame()\n",
    "pos_cols = ['pos_cnt_'+pos for pos in all_pos] \n",
    "\n",
    "#update pos counts\n",
    "complete_last = 0\n",
    "for i,doc in df.iterrows():    \n",
    "    \n",
    "    complete = round((i/df.shape[0])*100)\n",
    "    if complete != complete_last:\n",
    "        if complete % 2 == 0:\n",
    "            print('%s%%' % complete)\n",
    "            complete_last = complete\n",
    "    \n",
    "    #create empty dictionary with keys\n",
    "    pos_dict = dict.fromkeys(all_pos)\n",
    "    \n",
    "    for pos in doc['pos_data'].keys():\n",
    "        pos_dict[pos] = doc['pos_data'].get(pos)\n",
    "    \n",
    "    row = list(pos_dict.values())\n",
    "    row = pd.Series(row, index=pos_cols)\n",
    "    row = pd.DataFrame(row).T\n",
    "    df_pos = df_pos.append(row, ignore_index=True)\n",
    "    \n",
    "df = pd.merge(df, df_pos, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert ne counts to features\n",
    "- print percent complete\n",
    "- run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0%\n",
      "4.0%\n",
      "6.0%\n",
      "8.0%\n",
      "10.0%\n",
      "12.0%\n",
      "14.0%\n",
      "16.0%\n",
      "18.0%\n",
      "20.0%\n",
      "22.0%\n",
      "24.0%\n",
      "26.0%\n",
      "28.0%\n",
      "30.0%\n",
      "32.0%\n",
      "34.0%\n",
      "36.0%\n",
      "38.0%\n",
      "40.0%\n",
      "42.0%\n",
      "44.0%\n",
      "46.0%\n",
      "48.0%\n",
      "50.0%\n",
      "52.0%\n",
      "54.0%\n",
      "56.0%\n",
      "58.0%\n",
      "60.0%\n",
      "62.0%\n",
      "64.0%\n",
      "66.0%\n",
      "68.0%\n",
      "70.0%\n",
      "72.0%\n",
      "74.0%\n",
      "76.0%\n",
      "78.0%\n",
      "80.0%\n",
      "82.0%\n",
      "84.0%\n",
      "86.0%\n",
      "88.0%\n",
      "90.0%\n",
      "92.0%\n",
      "94.0%\n",
      "96.0%\n",
      "98.0%\n",
      "100.0%\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#get all named entities counts, add as features\n",
    "all_nes = []\n",
    "for i,doc in df.iterrows():\n",
    "    all_nes.extend(list(doc['nes_data'].keys()))\n",
    "\n",
    "#get unique\n",
    "all_nes = list(set(all_nes))\n",
    "\n",
    "#create nes feature df\n",
    "df_nes = pd.DataFrame()\n",
    "ne_cols = ['ne_cnt_'+ne for ne in all_nes] \n",
    "    \n",
    "#update pos counts\n",
    "complete_last = 0\n",
    "for i,doc in df.iterrows():    \n",
    "    \n",
    "    complete = round((i/df.shape[0])*100)\n",
    "    if complete != complete_last:\n",
    "        if complete % 2 == 0:\n",
    "            print('%s%%' % complete)\n",
    "            complete_last = complete\n",
    "    \n",
    "    #create empty dictionary with keys\n",
    "    nes_dict = dict.fromkeys(all_nes)\n",
    "    \n",
    "    for ne in doc['nes_data'].keys():\n",
    "        nes_dict[ne] = doc['nes_data'].get(ne)\n",
    "    \n",
    "    row = list(nes_dict.values())\n",
    "    row = pd.Series(row, index=ne_cols)\n",
    "    row = pd.DataFrame(row).T\n",
    "    df_nes = df_nes.append(row, ignore_index=True)\n",
    "    \n",
    "df = pd.merge(df, df_nes, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 104)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master_id</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>place_country</th>\n",
       "      <th>place_name</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_cnt_UH</th>\n",
       "      <th>pos_cnt_:</th>\n",
       "      <th>pos_cnt_JJR</th>\n",
       "      <th>pos_cnt_RBS</th>\n",
       "      <th>pos_cnt_WRB</th>\n",
       "      <th>pos_cnt_JJ</th>\n",
       "      <th>pos_cnt_CC</th>\n",
       "      <th>pos_cnt_POS</th>\n",
       "      <th>pos_cnt_CD</th>\n",
       "      <th>pos_cnt_PRP$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>726929577155526657</td>\n",
       "      <td>2016-05-02 00:21:31</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#IndianaPrimary..why would anyone pay $353K to...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   master_id          twitter_id           created_at               source  \\\n",
       "0        101  726929577155526657  2016-05-02 00:21:31  Twitter for Android   \n",
       "\n",
       "   longitude  latitude place_country place_name  \\\n",
       "0        NaN       NaN           NaN        NaN   \n",
       "\n",
       "                                                text lang      ...       \\\n",
       "0  #IndianaPrimary..why would anyone pay $353K to...   en      ...        \n",
       "\n",
       "  pos_cnt_UH pos_cnt_:  pos_cnt_JJR  pos_cnt_RBS  pos_cnt_WRB pos_cnt_JJ  \\\n",
       "0        3.0       NaN          1.0          NaN          1.0        4.0   \n",
       "\n",
       "  pos_cnt_CC pos_cnt_POS pos_cnt_CD  pos_cnt_PRP$  \n",
       "0        NaN         NaN        1.0           NaN  \n",
       "\n",
       "[1 rows x 104 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    " 'tweet_type',\n",
    " 'possibly_sensitive',\n",
    " 'is_retweet',\n",
    " 'is_reply',\n",
    " 'is_quoted_tweet',\n",
    " 'favorite_count',\n",
    " 'retweet_count',\n",
    " 'user_default_profile',\n",
    " 'user_default_profile_image',\n",
    " 'user_verified',\n",
    " 'user_statuses',\n",
    " 'user_favourites',\n",
    " 'user_followers',\n",
    " 'user_friends',\n",
    " 'user_listed',\n",
    " 'user_bio_len',\n",
    " 'user_reputation',\n",
    " 'user_age_days',\n",
    " 'user_follower_rate',\n",
    " 'count_entities_media',\n",
    " 'count_entities_urls',\n",
    " 'count_entities_mentions',\n",
    " 'count_entities_hashtags',\n",
    " 'count_characters',\n",
    " 'count_non_characters',\n",
    " 'count_upper',\n",
    " 'count_tokens',\n",
    " 'count_stops',\n",
    " 'question',\n",
    " 'elongation',\n",
    " 'ellipsis',\n",
    " 'lexical_diversity',\n",
    " 'sfpp',\n",
    " 'pfpp',\n",
    "# 'text_sentiment_polarity',\n",
    "# 'text_sentiment_subjectivity',\n",
    " 'topk_terms_coverage',\n",
    " 'tfidf_sum',\n",
    " 'tfidf_mean',\n",
    " 'event_centroid_distance',\n",
    " 'pos_cnt',\n",
    " 'nes_cnt',\n",
    " 'pos_cnt_MD',\n",
    " 'pos_cnt_SYM',\n",
    " 'pos_cnt_(',\n",
    " 'pos_cnt_$',\n",
    " 'pos_cnt_,',\n",
    " 'pos_cnt_WDT',\n",
    " 'pos_cnt_PDT',\n",
    " 'pos_cnt_JJS',\n",
    " 'pos_cnt_VBD',\n",
    " 'pos_cnt_RB',\n",
    " 'pos_cnt_DT',\n",
    " 'pos_cnt_VB',\n",
    " 'pos_cnt_VBP',\n",
    " 'pos_cnt_VBG',\n",
    " 'pos_cnt_.',\n",
    " 'pos_cnt_TO',\n",
    " 'pos_cnt_EX',\n",
    " 'pos_cnt_IN',\n",
    " 'pos_cnt_NNP',\n",
    " 'pos_cnt_VBN',\n",
    " 'pos_cnt_NN',\n",
    " 'pos_cnt_WP',\n",
    " 'pos_cnt_RP',\n",
    " 'pos_cnt_VBZ',\n",
    " 'pos_cnt_``',\n",
    " 'pos_cnt_)',\n",
    " 'pos_cnt_NNS',\n",
    " 'pos_cnt_PRP',\n",
    " 'pos_cnt_UH',\n",
    " 'pos_cnt_:',\n",
    " 'pos_cnt_JJR',\n",
    " 'pos_cnt_RBS',\n",
    " 'pos_cnt_WRB',\n",
    " 'pos_cnt_JJ',\n",
    " 'pos_cnt_CC',\n",
    " 'pos_cnt_POS',\n",
    " 'pos_cnt_CD',\n",
    " 'pos_cnt_PRP$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ycols = [\n",
    "#'y_question',\n",
    "#'y_advertisement',\n",
    "'y_opinion',\n",
    "#'y_sarcasm',\n",
    "#'y_content',\n",
    "'y_update']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[xcols] = df[xcols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save event data with features\n",
    "df.to_csv('data/final/event_indianaprimary_data_train.txt', sep='\\t', encoding='utf-8', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 104)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 200\n",
      "train: 160 (80%)\n",
      "test: 40 (20%)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=.2)\n",
    "\n",
    "dat = df.shape[0]\n",
    "tr = len(train)\n",
    "te = len(test)\n",
    "print('data: %s' % dat)\n",
    "print('train: %s (%s%%)' % (tr, round(100*tr/dat)))\n",
    "print('test: %s (%s%%)' % (te, round(100*te/dat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 78)\n",
      "(40, 78)\n"
     ]
    }
   ],
   "source": [
    "train_features = train[features]\n",
    "print(train_features.shape)\n",
    "test_features = test[features]\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict news update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "train_update = train['y_update']\n",
    "print(train_update.shape)\n",
    "test_update = test['y_update']\n",
    "print(test_update.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16674a58>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6MAAADdCAYAAABOpqQwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5dEUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164c7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "plt.subplot(1,3,1)\n",
    "df['y_update'].value_counts(normalize=True).plot(kind='bar', ylim=(0,1), title='Total Ys = %s' % df[df['y_update']==1].shape[0])\n",
    "plt.subplot(1,3,2)\n",
    "train_update.value_counts(normalize=True).plot(kind='bar', ylim=(0,1), title='Total Ys = %s' % train_update[train_actual==1].shape[0])\n",
    "plt.subplot(1,3,3)\n",
    "test_update.value_counts(normalize=True).plot(kind='bar', ylim=(0,1), title='Total Ys = %s' % test_update[test_actual==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize report\n",
    "def run_report(test_features, test_actual, model):\n",
    "    #predict test data\n",
    "    test_predictions = model.predict(test_features)\n",
    "    #results\n",
    "    print('Accuracy:', sklearn.metrics.accuracy_score(test_actual, test_predictions))\n",
    "    print('Confusion Matrix: \\n')\n",
    "    print(pd.crosstab(test_actual, test_predictions, rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "    print()\n",
    "    print('Report:')\n",
    "    print(classification_report(test_actual, test_predictions))\n",
    "\n",
    "    scores = cross_val_score(model,\n",
    "                             test_features,\n",
    "                             test_actual,\n",
    "                             scoring='accuracy')\n",
    "    print('Accuracy Scores:', scores)\n",
    "    print('mean:', scores.mean())\n",
    "    print('std:', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "- Multinomial Naive Bayes significantly outperforms Gaussian model. Although Multinomial requires non-negative features, and therefore sentiment features were left out of custom feature model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pipe = Pipeline([('count_vect', CountVectorizer()), \n",
    "                     ('X_tfidf', TfidfTransformer()), \n",
    "                     ('classifier', MultinomialNB())])\n",
    "\n",
    "MNB_tfidf = clf_pipe.fit(train['text'], train_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB TFIDF - Multinomial Naive Bayes using Bag of Words:\n",
      "\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  All\n",
      "Actual             \n",
      "0.0         30   30\n",
      "1.0          1    1\n",
      "2.0          9    9\n",
      "All         40   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      1.00      0.86        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.56      0.75      0.64        40\n",
      "\n",
      "Accuracy Scores: [ 0.71428571  0.76923077  0.76923077]\n",
      "mean: 0.750915750916\n",
      "std: 0.0259013472962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('MNB TFIDF - Multinomial Naive Bayes using Bag of Words:')\n",
    "print()\n",
    "run_report(test['text'], test_update, MNB_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB - Multinomial Naive Bayes:\n",
      "\n",
      "Accuracy: 0.6\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  1.0  2.0  All\n",
      "Actual                       \n",
      "0.0         23    5    2   30\n",
      "1.0          1    0    0    1\n",
      "2.0          5    3    1    9\n",
      "All         29    8    3   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.77      0.78        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.33      0.11      0.17         9\n",
      "\n",
      "avg / total       0.67      0.60      0.62        40\n",
      "\n",
      "Accuracy Scores: [ 0.5         0.69230769  0.61538462]\n",
      "mean: 0.602564102564\n",
      "std: 0.079030948756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('MNB - Multinomial Naive Bayes:')\n",
    "print()\n",
    "MNB = MultinomialNB().fit(train_features, train_update)\n",
    "run_report(test_features, test_update, MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - K Nearest Neighbor:\n",
      "\n",
      "Accuracy: 0.775\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  2.0  All\n",
      "Actual                  \n",
      "0.0         28    2   30\n",
      "1.0          1    0    1\n",
      "2.0          6    3    9\n",
      "All         35    5   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.93      0.86        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.60      0.33      0.43         9\n",
      "\n",
      "avg / total       0.73      0.78      0.74        40\n",
      "\n",
      "Accuracy Scores: [ 0.71428571  0.46153846  0.76923077]\n",
      "mean: 0.648351648352\n",
      "std: 0.133987847313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('KNN - K Nearest Neighbor:')\n",
    "print()\n",
    "KNN = KNeighborsClassifier().fit(train_features, train_update)\n",
    "run_report(test_features, test_update, KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC - Decision Tree:\n",
      "\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  1.0  2.0  All\n",
      "Actual                       \n",
      "0.0         27    1    2   30\n",
      "1.0          1    0    0    1\n",
      "2.0          6    0    3    9\n",
      "All         34    1    5   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.90      0.84        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.60      0.33      0.43         9\n",
      "\n",
      "avg / total       0.73      0.75      0.73        40\n",
      "\n",
      "Accuracy Scores: [ 0.64285714  0.69230769  0.53846154]\n",
      "mean: 0.624542124542\n",
      "std: 0.064128723077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('DTC - Decision Tree:')\n",
    "print()\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=2016).fit(train_features, train_update)\n",
    "run_report(test_features, test_update, DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC - Random Forest:\n",
      "\n",
      "Accuracy: 0.8\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  2.0  All\n",
      "Actual                  \n",
      "0.0         30    0   30\n",
      "1.0          1    0    1\n",
      "2.0          7    2    9\n",
      "All         38    2   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      1.00      0.88        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       1.00      0.22      0.36         9\n",
      "\n",
      "avg / total       0.82      0.80      0.74        40\n",
      "\n",
      "Accuracy Scores: [ 0.71428571  0.76923077  0.84615385]\n",
      "mean: 0.776556776557\n",
      "std: 0.0540836009532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('RFC - Random Forest:')\n",
    "print()\n",
    "#defualt 10 trees\n",
    "RFC = RandomForestClassifier(random_state=2016).fit(train_features, train_update)\n",
    "run_report(test_features, test_update, RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - Support Vector Machine:\n",
      "\n",
      "Accuracy: 0.75\n",
      "Confusion Matrix: \n",
      "\n",
      "Predicted  0.0  All\n",
      "Actual             \n",
      "0.0         30   30\n",
      "1.0          1    1\n",
      "2.0          9    9\n",
      "All         40   40\n",
      "\n",
      "Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      1.00      0.86        30\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.56      0.75      0.64        40\n",
      "\n",
      "Accuracy Scores: [ 0.71428571  0.76923077  0.76923077]\n",
      "mean: 0.750915750916\n",
      "std: 0.0259013472962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "print('SVC - Support Vector Machine:')\n",
    "print()\n",
    "#defualt 10 trees\n",
    "SVC = svm.SVC().fit(train_features, train_update)\n",
    "run_report(test_features, test_update, SVC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
