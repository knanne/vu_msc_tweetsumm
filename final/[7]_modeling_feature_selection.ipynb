{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    " 'favorite_count',\n",
    " 'retweet_count',\n",
    " 'entities_count_hashtags',\n",
    " 'entities_count_symbols',\n",
    " 'entities_count_urls',\n",
    " 'entities_count_user_mentions',\n",
    " 'user_id_verified',\n",
    " 'user_id_statuses_count',\n",
    " 'user_id_favourites_count',\n",
    " 'user_id_followers_count',\n",
    " 'user_id_friends_count',\n",
    " 'user_id_listed_count',\n",
    " 'count_words',\n",
    " 'count_stops',\n",
    " 'count_characters',\n",
    " 'count_non_characters',\n",
    " 'count_upper',\n",
    " 'bool_question',\n",
    " 'bool_elongation',\n",
    " 'bool_ellipsis',\n",
    " 'lexical_diversity',\n",
    " 'query_grams_coverage',\n",
    " 'topk_terms_coverage',\n",
    " 'tfidf_sum',\n",
    " 'tfidf_mean',\n",
    " 'event_centroid_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2902: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2295892, 37)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_table('data/final/event_panama_papers_data.txt', sep='\\t', encoding='utf-8', header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['user_id_verified'] = df['user_id_verified'].astype(object).replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load annotated data\n",
    "df_ann = pd.read_table('data/final/cf_report_pp_test100.csv', sep=',', encoding='utf-8', header=0)\n",
    "df_ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove bad data\n",
    "#-1 was loading error in annotation\n",
    "df_ann = df_ann[(df_ann['1_is_of_high_quality'] != -1) & (df_ann['2_is_informative'] != -1) & (df_ann['3_relevant_to_event'] != -1)]\n",
    "df_ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user class names for reporting\n",
    "target_names=['No', 'Maybe', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get classes on master id\n",
    "df_y = df_ann[['master_id', '1_is_of_high_quality', '2_is_informative', '3_relevant_to_event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add anotations to data\n",
    "df_ann = pd.merge(df, df_y, on='master_id')\n",
    "df_ann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 99\n",
      "train: 59 (60%)\n",
      "test: 15 (15%)\n"
     ]
    }
   ],
   "source": [
    "#split\n",
    "#train, test = train_test_split(df_ann, test_size=.2)\n",
    "#use only extreme classes \"No\"=0 or \"Yes\"=3\n",
    "#separation is larger, model accuracy is higher\n",
    "#train, test = train_test_split(df_ann[df_ann['1_is_of_high_quality'].isin([0,2])], test_size=.2)\n",
    "#train, test = train_test_split(df_ann[df_ann['2_is_informative'].isin([0,2])], test_size=.2)\n",
    "train, test = train_test_split(df_ann[df_ann['3_relevant_to_event'].isin([0,2])], test_size=.2)\n",
    "\n",
    "dat = df_ann.shape[0]\n",
    "tr = len(train)\n",
    "te = len(test)\n",
    "print('data: %s' % dat)\n",
    "print('train: %s (%s%%)' % (tr, round(100*tr/dat)))\n",
    "print('test: %s (%s%%)' % (te, round(100*te/dat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_quality = train['1_is_of_high_quality']\n",
    "#train_informative = train['2_is_informative']\n",
    "train_relevant = train['3_relevant_to_event']\n",
    "train_features = train[features]\n",
    "\n",
    "#test_quality = test['1_is_of_high_quality']\n",
    "#test_informative = test['2_is_informative']\n",
    "test_relevant = test['3_relevant_to_event']\n",
    "test_features = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 26)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relevant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Execute Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bag of words features using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build pipeline for easy classifying using tfidf bag of words\n",
    "clf_pipe = Pipeline([('count_vect', CountVectorizer()), \n",
    "                     ('X_tfidf', TfidfTransformer()), \n",
    "                     ('classifier', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = clf_pipe.fit(train['text'], train_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = text_clf.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         3\n",
      "          2       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.64      0.80      0.71        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_relevant, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(text_clf,\n",
    "                         train['text'],\n",
    "                         train_relevant,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB BOW TF-IDF Model\n",
      "accuracy scores: [ 0.47619048  0.42105263  0.68421053]\n",
      "mean: 0.527151211362\n",
      "std: 0.113315979419\n"
     ]
    }
   ],
   "source": [
    "print('MNB BOW TF-IDF Model')\n",
    "print('accuracy scores:', scores)\n",
    "print('mean:', scores.mean())\n",
    "print('std:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create using custom twitter features\n",
    "MNB_classifier = MultinomialNB().fit(train_features, train_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4\n",
      "confusion matrix\n",
      " [[1 2]\n",
      " [7 5]]\n"
     ]
    }
   ],
   "source": [
    "#predict test data\n",
    "test_predictions = MNB_classifier.predict(test_features)\n",
    "#results\n",
    "print('accuracy', sklearn.metrics.accuracy_score(test_relevant, test_predictions))\n",
    "print('confusion matrix\\n', sklearn.metrics.confusion_matrix(test_relevant, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.12      0.33      0.18         3\n",
      "          2       0.71      0.42      0.53        12\n",
      "\n",
      "avg / total       0.60      0.40      0.46        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_relevant, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(MNB_classifier,\n",
    "                         train_features,\n",
    "                         train_relevant,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Custom Model\n",
      "accuracy scores: [ 0.47619048  0.42105263  0.68421053]\n",
      "mean: 0.527151211362\n",
      "std: 0.113315979419\n"
     ]
    }
   ],
   "source": [
    "print('MNB Custom Model')\n",
    "print('accuracy scores:', scores)\n",
    "print('mean:', scores.mean())\n",
    "print('std:', scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
