{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_name = '[TEDxNations]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_table('data/%s_data_clean_features.txt' % event_name, sep='\\t', header=0, encoding='utf-8')\n",
    "event_data_class = pd.read_table('data/%s_data_clean_annotated.txt' % event_name, sep='\\t', header=0, encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_data = pd.merge(event_data, event_data_class, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove data without annotation\n",
    "event_data = event_data[event_data['Class'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = ['count_links',\n",
    "                 'count_hashtags',\n",
    "                 'count_mentions',\n",
    "                 'count_words',\n",
    "                 'count_characters',\n",
    "                 'count_non_characters',\n",
    "                 'count_upper',\n",
    "                 'bool_question',\n",
    "                 'bool_elongation',\n",
    "                 'bool_ellipsis',\n",
    "                 't_distinct',\n",
    "                 't_sum',\n",
    "                 'tfidf_sum',\n",
    "                 'tfidf_mean',\n",
    "                 'pos_cnt',\n",
    "                 'nes_cnt',\n",
    "                 'pos_cnt_NN',\n",
    "                 'pos_cnt_RP',\n",
    "                 'pos_cnt_POS',\n",
    "                 'pos_cnt_VB',\n",
    "                 'pos_cnt_(',\n",
    "                 'pos_cnt_``',\n",
    "                 \"pos_cnt_''\",\n",
    "                 'pos_cnt_WP',\n",
    "                 'pos_cnt_VBD',\n",
    "                 'pos_cnt_NNPS',\n",
    "                 'pos_cnt_NNP',\n",
    "                 'pos_cnt_.',\n",
    "                 'pos_cnt_JJR',\n",
    "                 'pos_cnt_CC',\n",
    "                 'pos_cnt_EX',\n",
    "                 'pos_cnt_PDT',\n",
    "                 'pos_cnt_DT',\n",
    "                 'pos_cnt_WRB',\n",
    "                 'pos_cnt_PRP$',\n",
    "                 'pos_cnt_)',\n",
    "                 'pos_cnt_SYM',\n",
    "                 'pos_cnt_RBR',\n",
    "                 'pos_cnt_VBP',\n",
    "                 'pos_cnt_FW',\n",
    "                 'pos_cnt_CD',\n",
    "                 'pos_cnt_JJ',\n",
    "                 'pos_cnt_$',\n",
    "                 'pos_cnt_WDT',\n",
    "                 'pos_cnt_JJS',\n",
    "                 'pos_cnt_VBN',\n",
    "                 'pos_cnt_RBS',\n",
    "                 'pos_cnt_IN',\n",
    "                 'pos_cnt_,',\n",
    "                 'pos_cnt_UH',\n",
    "                 'pos_cnt_PRP',\n",
    "                 'pos_cnt_VBG',\n",
    "                 'pos_cnt_TO',\n",
    "                 'pos_cnt_VBZ',\n",
    "                 'pos_cnt_MD',\n",
    "                 'pos_cnt_NNS',\n",
    "                 'pos_cnt_RB',\n",
    "                 'pos_cnt_:',\n",
    "                 'ne_cnt_PERSON',\n",
    "                 'ne_cnt_GSP',\n",
    "                 'ne_cnt_ORGANIZATION',\n",
    "                 'ne_cnt_GPE',\n",
    "                 'ne_cnt_LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 263\n",
      "train: 210 (80%)\n",
      "test: 53 (20%)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(event_data, test_size=.2)\n",
    "\n",
    "dat = event_data.shape[0]\n",
    "tr = len(train)\n",
    "te = len(test)\n",
    "print('data: %s' % dat)\n",
    "print('train: %s (%s%%)' % (tr, round(100*tr/dat)))\n",
    "print('test: %s (%s%%)' % (te, round(100*te/dat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_class = train['Class']\n",
    "train_features = train[feature_cols]\n",
    "\n",
    "test_class = test['Class']\n",
    "test_features = test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build pipeline for easy classifying using tfidf bag of words\n",
    "pipeline = Pipeline([('count_vect', CountVectorizer()), \n",
    "                     ('X_tfidf', TfidfTransformer()), \n",
    "                     ('classifier', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline,\n",
    "                         train['text'],\n",
    "                         train_class,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf bow model\n",
      "accuracy scores: [ 0.63380282  0.64285714  0.65217391]\n",
      "mean: 0.642944624267\n",
      "std: 0.00750022369058\n"
     ]
    }
   ],
   "source": [
    "print('tfidf bow model')\n",
    "print('accuracy scores:', scores)\n",
    "print('mean:', scores.mean())\n",
    "print('std:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create using original features\n",
    "classifier = MultinomialNB().fit(train_features, train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test on train !!!BAD!!!\n",
    "train_predictions = classifier.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.695238095238\n",
      "confusion matrix\n",
      " [[  0   1   0]\n",
      " [  0 112  23]\n",
      " [  0  40  34]]\n"
     ]
    }
   ],
   "source": [
    "#GARBAGE Model i.e. annotation data (can't predict good on training data)\n",
    "print('accuracy', sklearn.metrics.accuracy_score(train_class, train_predictions))\n",
    "print('confusion matrix\\n', sklearn.metrics.confusion_matrix(train_class, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.73      0.83      0.78       135\n",
      "        3.0       0.60      0.46      0.52        74\n",
      "\n",
      "avg / total       0.68      0.70      0.68       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(train_class, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "test_predictions = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.584905660377\n",
      "confusion matrix\n",
      " [[ 0  1  0]\n",
      " [ 0 26  8]\n",
      " [ 0 13  5]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', sklearn.metrics.accuracy_score(test_class, test_predictions))\n",
    "print('confusion matrix\\n', sklearn.metrics.confusion_matrix(test_class, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: RT unfoundation: \"Smoke inhalation from cooking results in 4 millions deaths per year\" -RanyeeCleanCook | #TEDxNations #cleancooking\n",
      "\n",
      "predicted: 2.0\n",
      "actual: 3.0\n"
     ]
    }
   ],
   "source": [
    "#check random test doc index\n",
    "i = 20\n",
    "print('doc:', test.iloc[i]['text'])\n",
    "print()\n",
    "print('predicted:', test_predictions[i])\n",
    "print('actual:', test_class.iloc[i]) # or test.iloc[i]['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00         1\n",
      "        2.0       0.65      0.76      0.70        34\n",
      "        3.0       0.38      0.28      0.32        18\n",
      "\n",
      "avg / total       0.55      0.58      0.56        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(test_class, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
