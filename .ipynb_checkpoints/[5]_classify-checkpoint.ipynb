{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_name = '[egyptair]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_table('data/%s_data_clean_features.txt' % event_name, sep='\\t', header=0, encoding='utf-8')\n",
    "event_data_class = pd.read_table('data/%s_data_clean_annotated.txt' % event_name, sep='\\t', header=0, encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_data = pd.merge(event_data, event_data_class, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove data without annotation\n",
    "event_data = event_data[event_data['class'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = ['count_links',\n",
    "                 'count_hashtags',\n",
    "                 'count_mentions',\n",
    "                 'count_words',\n",
    "                 'count_characters',\n",
    "                 'count_non_characters',\n",
    "                 'count_upper',\n",
    "                 'bool_question',\n",
    "                 'bool_elongation',\n",
    "                 'bool_ellipsis',\n",
    "                 't_distinct',\n",
    "                 't_sum',\n",
    "                 'tfidf_sum',\n",
    "                 'tfidf_mean',\n",
    "                 'pos_cnt',\n",
    "                 'nes_cnt',\n",
    "                 'pos_cnt_NN',\n",
    "                 'pos_cnt_RP',\n",
    "                 'pos_cnt_POS',\n",
    "                 'pos_cnt_VB',\n",
    "                 'pos_cnt_(',\n",
    "                 'pos_cnt_``',\n",
    "                 \"pos_cnt_''\",\n",
    "                 'pos_cnt_WP',\n",
    "                 'pos_cnt_VBD',\n",
    "                 'pos_cnt_NNPS',\n",
    "                 'pos_cnt_NNP',\n",
    "                 'pos_cnt_.',\n",
    "                 'pos_cnt_JJR',\n",
    "                 'pos_cnt_CC',\n",
    "                 'pos_cnt_EX',\n",
    "                 'pos_cnt_PDT',\n",
    "                 'pos_cnt_DT',\n",
    "                 'pos_cnt_WRB',\n",
    "                 'pos_cnt_PRP$',\n",
    "                 'pos_cnt_)',\n",
    "                 'pos_cnt_SYM',\n",
    "                 'pos_cnt_RBR',\n",
    "                 'pos_cnt_VBP',\n",
    "                 'pos_cnt_FW',\n",
    "                 'pos_cnt_CD',\n",
    "                 'pos_cnt_JJ',\n",
    "                 'pos_cnt_$',\n",
    "                 'pos_cnt_WDT',\n",
    "                 'pos_cnt_JJS',\n",
    "                 'pos_cnt_VBN',\n",
    "                 'pos_cnt_RBS',\n",
    "                 'pos_cnt_IN',\n",
    "                 'pos_cnt_,',\n",
    "                 'pos_cnt_UH',\n",
    "                 'pos_cnt_PRP',\n",
    "                 'pos_cnt_VBG',\n",
    "                 'pos_cnt_TO',\n",
    "                 'pos_cnt_VBZ',\n",
    "                 'pos_cnt_MD',\n",
    "                 'pos_cnt_NNS',\n",
    "                 'pos_cnt_RB',\n",
    "                 'pos_cnt_:',\n",
    "                 'ne_cnt_PERSON',\n",
    "                 'ne_cnt_GSP',\n",
    "                 'ne_cnt_ORGANIZATION',\n",
    "                 'ne_cnt_GPE',\n",
    "                 'ne_cnt_LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 186\n",
      "train: 148 (80%)\n",
      "test: 38 (20%)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(event_data, test_size=.2)\n",
    "\n",
    "dat = event_data.shape[0]\n",
    "tr = len(train)\n",
    "te = len(test)\n",
    "print('data: %s' % dat)\n",
    "print('train: %s (%s%%)' % (tr, round(100*tr/dat)))\n",
    "print('test: %s (%s%%)' % (te, round(100*te/dat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_class = train['class']\n",
    "train_features = train[feature_cols]\n",
    "\n",
    "test_class = test['class']\n",
    "test_features = test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build pipeline for easy classifying using tfidf bag of words\n",
    "pipeline = Pipeline([('count_vect', CountVectorizer()), \n",
    "                     ('X_tfidf', TfidfTransformer()), \n",
    "                     ('classifier', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline,\n",
    "                         train['text'],\n",
    "                         train_class,\n",
    "                         scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf bow model\n",
      "accuracy scores: [ 0.80769231  0.77083333  0.72916667]\n",
      "mean: 0.769230769231\n",
      "std: 0.0320779803333\n"
     ]
    }
   ],
   "source": [
    "print('tfidf bow model')\n",
    "print('accuracy scores:', scores)\n",
    "print('mean:', scores.mean())\n",
    "print('std:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create using original features\n",
    "classifier = MultinomialNB().fit(train_features, train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test on train !!!BAD!!!\n",
    "train_predictions = classifier.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.736486486486\n",
      "confusion matrix\n",
      " [[ 2  0  0  0  2]\n",
      " [ 0 64  1  0 11]\n",
      " [ 0  2 10  0  6]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  8  8  0 33]]\n"
     ]
    }
   ],
   "source": [
    "#GARBAGE Model i.e. annotation data (can't predict good on training data)\n",
    "print('accuracy', sklearn.metrics.accuracy_score(train_class, train_predictions))\n",
    "print('confusion matrix\\n', sklearn.metrics.confusion_matrix(train_class, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.50      0.67         4\n",
      "        1.0       0.86      0.84      0.85        76\n",
      "        2.0       0.50      0.56      0.53        18\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "        4.0       0.63      0.67      0.65        49\n",
      "\n",
      "avg / total       0.74      0.74      0.74       148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(train_class, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "test_predictions = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.657894736842\n",
      "confusion matrix\n",
      " [[ 1  0  0  0  1]\n",
      " [ 1 13  1  0  3]\n",
      " [ 0  1  2  0  3]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  2  0  9]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', sklearn.metrics.accuracy_score(test_class, test_predictions))\n",
    "print('confusion matrix\\n', sklearn.metrics.confusion_matrix(test_class, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: This man will surely have a story to tell his grand children #EgyptAir\n",
      "\n",
      "predicted: 1.0\n",
      "actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "#check random test doc index\n",
    "i = 20\n",
    "print('doc:', test.iloc[i]['text'])\n",
    "print()\n",
    "print('predicted:', test_predictions[i])\n",
    "print('actual:', test_class.iloc[i]) # or test.iloc[i]['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.50      0.50         2\n",
      "        1.0       0.93      0.72      0.81        18\n",
      "        2.0       0.33      0.33      0.33         6\n",
      "        3.0       0.00      0.00      0.00         1\n",
      "        4.0       0.56      0.82      0.67        11\n",
      "\n",
      "avg / total       0.68      0.66      0.66        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(test_class, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
