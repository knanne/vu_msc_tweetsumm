{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TERM FREQUENCY - tf sub(t,d) = sum of occurences term (t) in doc (d)\n",
    "#DOCUMENT FREQUENCY - df sub(t) = sum of docs (d) in collection containing term (t)\n",
    "#INVERSE DOCUMENT FREQUENCY - idf sub(t) = log of total docs in collection (N) over document frequency\n",
    "#WEIGHTED TF-IDF - tf-idf sub(t,d) - sum of occurences term (t) in doc (d) times inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elongated = re.compile('([a-zA-Z])\\\\1{2,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_name = '[TEDxNations]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_table('%s_data_clean.txt' % event_name, sep='\\t', header=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add basic count features\n",
    "event_data['count_links'] = event_data['text'].apply(lambda text: len([w for w in text.split() if w.startswith(('http://', 'https://'))]))\n",
    "event_data['count_hashtags'] = event_data['text'].apply(lambda text: len([w for w in text.split() if w.startswith('#')]))\n",
    "event_data['count_mentions'] = event_data['text'].apply(lambda text: len([w for w in text.split() if w.startswith('@')]))\n",
    "event_data['count_words'] = event_data['text'].apply(lambda text: len([w for w in text.split() if not w.startswith(('RT', '@', '#'))]))\n",
    "event_data['count_characters'] = event_data['text'].apply(lambda text: len(str(text)))\n",
    "event_data['count_non_characters'] = event_data['text_nolink'].apply(lambda text: len(re.sub('[\\w+!@#$%&;:,.?\\/\\-“”’`\"\\'()|]', '', text).strip()))\n",
    "event_data['count_upper'] = event_data['text_nolink'].apply(lambda text: len([l for l in ' '.join([w for w in text.split() if not w.startswith(('#', '@'))]) if l.isupper()]))\n",
    "event_data['bool_question'] = event_data['text_clean'].apply(lambda text: 1 if '?' in text else 0)\n",
    "event_data['bool_elongation'] = event_data['text_clean'].apply(lambda text: 1 if bool(elongated.search(text)) else 0)\n",
    "event_data['bool_ellipsis'] = event_data['text_clean'].apply(lambda text: 1 if any(x in text for x in ('...', '…')) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute top tokens\n",
    "def gather_tokens(data):\n",
    "    all_tokens = []\n",
    "    for doc in data:\n",
    "        tokens = doc.split()\n",
    "        all_tokens.extend(tokens)\n",
    "    return all_tokens\n",
    "\n",
    "#gather tokens from all docs \n",
    "all_tokens = gather_tokens(event_data['text_clean_tokens'])\n",
    "#create counter object\n",
    "tokens_cntr = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tedxnations', 1752),\n",
       " ('ungeneva', 283),\n",
       " ('tedxpdnations', 198),\n",
       " ('live', 167),\n",
       " ('11', 144),\n",
       " ('rt', 142),\n",
       " ('watch', 127),\n",
       " ('lagosviewingparty', 126),\n",
       " ('lives', 122),\n",
       " ('people', 106)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cntr.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize a vectorizer, require minimum freq. of terms at 2\n",
    "count_vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learn the vocabulary dictionary and return term-document matrix\n",
    "train_matrix_cnt = count_vect.fit_transform(event_data['text_clean_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit and Transform count sparse matrix to normalized tf-idf sparse matrix\n",
    "#first fit transformer which computes idf values\n",
    "tfidf_transformer = TfidfTransformer().fit(train_matrix_cnt)\n",
    "#second transform back to sparse matrix with tfidf values\n",
    "train_matrix_tfidf = tfidf_transformer.transform(train_matrix_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (1778, 1550)\n",
      "size: 2755900\n",
      "non-zeros: 15666\n",
      "sparsity: 99.43%\n",
      "density: 0.57%\n"
     ]
    }
   ],
   "source": [
    "#explore sparse matrix\n",
    "print('sparse matrix shape:', train_matrix_cnt.shape)\n",
    "print('size:', (train_matrix_cnt.shape[0] * train_matrix_cnt.shape[1]))\n",
    "print('non-zeros:', train_matrix_cnt.getnnz())\n",
    "print('sparsity: %.2f%%' % (100.0 * (((train_matrix_cnt.shape[0] * train_matrix_cnt.shape[1]) - train_matrix_cnt.getnnz()) / (train_matrix_cnt.shape[0] * train_matrix_cnt.shape[1]))))\n",
    "print('density: %.2f%%' % (100.0 * train_matrix_cnt.getnnz() / (train_matrix_cnt.shape[0] * train_matrix_cnt.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tf</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>5.0181</td>\n",
       "      <td>0.3031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icrc</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0498</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5.7112</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>globally</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.692</td>\n",
       "      <td>0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>address</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.9189</td>\n",
       "      <td>0.3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sexualviolence</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>4.2791</td>\n",
       "      <td>0.2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conflict</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5.4393</td>\n",
       "      <td>0.3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>learn</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5.6506</td>\n",
       "      <td>0.3413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tedxnations</td>\n",
       "      <td>1</td>\n",
       "      <td>1752</td>\n",
       "      <td>1.0142</td>\n",
       "      <td>0.0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>via</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.4881</td>\n",
       "      <td>0.3315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term tf    df     idf   tfidf\n",
       "0             how  1    31  5.0181  0.3031\n",
       "1            icrc  1    29  5.0498   0.305\n",
       "2            work  1    15  5.7112   0.345\n",
       "3        globally  1     5   6.692  0.4042\n",
       "4         address  1    12  5.9189  0.3575\n",
       "5  sexualviolence  1    66  4.2791  0.2585\n",
       "6        conflict  1    20  5.4393  0.3285\n",
       "7           learn  1    15  5.6506  0.3413\n",
       "8     tedxnations  1  1752  1.0142  0.0613\n",
       "9             via  1    19  5.4881  0.3315"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST EXAMPLE term frequencies\n",
    "data_index = 0\n",
    "\n",
    "data = pd.DataFrame(columns=['term', 'tf', 'df', 'idf', 'tfidf'])\n",
    "\n",
    "for feature_index in train_matrix_cnt[data_index].nonzero()[1]:\n",
    "    \n",
    "    term = count_vect.get_feature_names()[feature_index]\n",
    "    tf = train_matrix_cnt[data_index, feature_index]\n",
    "    df = tokens_cntr.get(term)\n",
    "    idf = round(tfidf_transformer.idf_[feature_index], 4)\n",
    "    tfidf = round(train_matrix_tfidf[data_index, feature_index], 4)\n",
    "    \n",
    "    row = [term, tf, df, idf, tfidf]\n",
    "    row = pd.Series(row, index=['term', 'tf', 'df', 'idf', 'tfidf'])\n",
    "    row = pd.DataFrame(row).T\n",
    "    data = data.append(row, ignore_index=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete\n",
      "2.81% complete\n",
      "5.62% complete\n",
      "8.44% complete\n",
      "11.25% complete\n",
      "14.06% complete\n",
      "16.87% complete\n",
      "19.69% complete\n",
      "22.5% complete\n",
      "25.31% complete\n",
      "28.12% complete\n",
      "30.93% complete\n",
      "33.75% complete\n",
      "36.56% complete\n",
      "39.37% complete\n",
      "42.18% complete\n",
      "44.99% complete\n",
      "47.81% complete\n",
      "50.62% complete\n",
      "53.43% complete\n",
      "56.24% complete\n",
      "59.06% complete\n",
      "61.87% complete\n",
      "64.68% complete\n",
      "67.49% complete\n",
      "70.3% complete\n",
      "73.12% complete\n",
      "75.93% complete\n",
      "78.74% complete\n",
      "81.55% complete\n",
      "84.36% complete\n",
      "87.18% complete\n",
      "89.99% complete\n",
      "92.8% complete\n",
      "95.61% complete\n",
      "98.43% complete\n",
      "100%% complete\n"
     ]
    }
   ],
   "source": [
    "#add aggregate tfidf to data\n",
    "event_data_tfidf = pd.DataFrame()\n",
    "\n",
    "for i,doc in event_data.iterrows():\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        complete = round((i/event_data.shape[0])*100, 2)\n",
    "        print('%s%% complete' % complete)\n",
    "    \n",
    "    tfs = train_matrix_cnt[i].data\n",
    "    tfidfs = train_matrix_tfidf[i].data\n",
    "    t_distinct = len(tfs)\n",
    "    t_sum = tfs.sum()\n",
    "    tfidf_sum = tfidfs.sum()\n",
    "    tfidf_mean = (0 if tfidf_sum == 0 else tfidfs.mean())\n",
    "\n",
    "    row = [t_distinct, t_sum, tfidf_sum, tfidf_mean]\n",
    "    row = pd.Series(row, index=['t_distinct', 't_sum', 'tfidf_sum', 'tfidf_mean'])\n",
    "    row = pd.DataFrame(row).T\n",
    "    event_data_tfidf = event_data_tfidf.append(row, ignore_index=True)\n",
    "    \n",
    "event_data = pd.merge(event_data, event_data_tfidf, left_index=True, right_index=True)\n",
    "print('100%% complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete\n",
      "2.81% complete\n",
      "5.62% complete\n",
      "8.44% complete\n",
      "11.25% complete\n",
      "14.06% complete\n",
      "16.87% complete\n",
      "19.69% complete\n",
      "22.5% complete\n",
      "25.31% complete\n",
      "28.12% complete\n",
      "30.93% complete\n",
      "33.75% complete\n",
      "36.56% complete\n",
      "39.37% complete\n",
      "42.18% complete\n",
      "44.99% complete\n",
      "47.81% complete\n",
      "50.62% complete\n",
      "53.43% complete\n",
      "56.24% complete\n",
      "59.06% complete\n",
      "61.87% complete\n",
      "64.68% complete\n",
      "67.49% complete\n",
      "70.3% complete\n",
      "73.12% complete\n",
      "75.93% complete\n",
      "78.74% complete\n",
      "81.55% complete\n",
      "84.36% complete\n",
      "87.18% complete\n",
      "89.99% complete\n",
      "92.8% complete\n",
      "95.61% complete\n",
      "98.43% complete\n",
      "100%% complete\n"
     ]
    }
   ],
   "source": [
    "#calculate and add parts of speech, named entities info to data\n",
    "event_data_nespos = pd.DataFrame()\n",
    "\n",
    "#define function for nltk tree mining\n",
    "def getnes(tree):\n",
    "    ne = []\n",
    "    for node in tree:\n",
    "        if type(node) is nltk.Tree:\n",
    "            label = node.label()\n",
    "            s = ''\n",
    "            for node in node:\n",
    "                s = (s + ' ' + node[0].lower()).lstrip()\n",
    "            ne.append([label, s])\n",
    "    return ne\n",
    "\n",
    "for i,doc in event_data.iterrows():\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        complete = round((i/event_data.shape[0])*100, 2)\n",
    "        print('%s%% complete' % complete)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(str(doc['text_clean']))\n",
    "    \n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    pos_cntr = Counter(list(dict(pos).values()))\n",
    "    pos_data = dict(pos_cntr)\n",
    "    pos_cnt = sum(pos_data.values())\n",
    "    \n",
    "    tree = nltk.ne_chunk(pos)\n",
    "    nes = getnes(tree)\n",
    "    nes_cntr = Counter(list(dict(nes).keys()))\n",
    "    nes_data = dict(nes_cntr)\n",
    "    nes_cnt = sum(nes_data.values())\n",
    "    \n",
    "    row = [pos_cnt, nes_cnt, pos_data, nes_data]\n",
    "    row = pd.Series(row, index=['pos_cnt', 'nes_cnt', 'pos_data', 'nes_data'])\n",
    "    row = pd.DataFrame(row).T\n",
    "    event_data_nespos = event_data_nespos.append(row, ignore_index=True)\n",
    "    \n",
    "event_data = pd.merge(event_data, event_data_nespos, left_index=True, right_index=True)\n",
    "print('100%% complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete\n",
      "2.81% complete\n",
      "5.62% complete\n",
      "8.44% complete\n",
      "11.25% complete\n",
      "14.06% complete\n",
      "16.87% complete\n",
      "19.69% complete\n",
      "22.5% complete\n",
      "25.31% complete\n",
      "28.12% complete\n",
      "30.93% complete\n",
      "33.75% complete\n",
      "36.56% complete\n",
      "39.37% complete\n",
      "42.18% complete\n",
      "44.99% complete\n",
      "47.81% complete\n",
      "50.62% complete\n",
      "53.43% complete\n",
      "56.24% complete\n",
      "59.06% complete\n",
      "61.87% complete\n",
      "64.68% complete\n",
      "67.49% complete\n",
      "70.3% complete\n",
      "73.12% complete\n",
      "75.93% complete\n",
      "78.74% complete\n",
      "81.55% complete\n",
      "84.36% complete\n",
      "87.18% complete\n",
      "89.99% complete\n",
      "92.8% complete\n",
      "95.61% complete\n",
      "98.43% complete\n",
      "100%% complete\n"
     ]
    }
   ],
   "source": [
    "#get all parts of speach\n",
    "all_pos = []\n",
    "for i,doc in event_data.iterrows():\n",
    "    all_pos.extend(list(doc['pos_data'].keys()))\n",
    "\n",
    "#get unique\n",
    "all_pos = list(set(all_pos))\n",
    "\n",
    "#create pos feature df\n",
    "event_data_pos = pd.DataFrame()\n",
    "pos_cols = ['pos_cnt_'+pos for pos in all_pos] \n",
    "\n",
    "#update pos counts\n",
    "for i,doc in event_data.iterrows():    \n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        complete = round((i/event_data.shape[0])*100, 2)\n",
    "        print('%s%% complete' % complete)\n",
    "    \n",
    "    #create empty dictionary with keys\n",
    "    pos_dict = dict.fromkeys(all_pos)\n",
    "    \n",
    "    for pos in doc['pos_data'].keys():\n",
    "        pos_dict[pos] = doc['pos_data'].get(pos)\n",
    "    \n",
    "    row = list(pos_dict.values())\n",
    "    row = pd.Series(row, index=pos_cols)\n",
    "    row = pd.DataFrame(row).T\n",
    "    event_data_pos = event_data_pos.append(row, ignore_index=True)\n",
    "    \n",
    "event_data = pd.merge(event_data, event_data_pos, left_index=True, right_index=True)\n",
    "print('100%% complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete\n",
      "2.81% complete\n",
      "5.62% complete\n",
      "8.44% complete\n",
      "11.25% complete\n",
      "14.06% complete\n",
      "16.87% complete\n",
      "19.69% complete\n",
      "22.5% complete\n",
      "25.31% complete\n",
      "28.12% complete\n",
      "30.93% complete\n",
      "33.75% complete\n",
      "36.56% complete\n",
      "39.37% complete\n",
      "42.18% complete\n",
      "44.99% complete\n",
      "47.81% complete\n",
      "50.62% complete\n",
      "53.43% complete\n",
      "56.24% complete\n",
      "59.06% complete\n",
      "61.87% complete\n",
      "64.68% complete\n",
      "67.49% complete\n",
      "70.3% complete\n",
      "73.12% complete\n",
      "75.93% complete\n",
      "78.74% complete\n",
      "81.55% complete\n",
      "84.36% complete\n",
      "87.18% complete\n",
      "89.99% complete\n",
      "92.8% complete\n",
      "95.61% complete\n",
      "98.43% complete\n",
      "100%% complete\n"
     ]
    }
   ],
   "source": [
    "#get all named entities\n",
    "all_nes = []\n",
    "for i,doc in event_data.iterrows():\n",
    "    all_nes.extend(list(doc['nes_data'].keys()))\n",
    "\n",
    "#get unique\n",
    "all_nes = list(set(all_nes))\n",
    "\n",
    "#create nes feature df\n",
    "event_data_nes = pd.DataFrame()\n",
    "ne_cols = ['ne_cnt_'+ne for ne in all_nes] \n",
    "    \n",
    "#update pos counts\n",
    "for i,doc in event_data.iterrows():    \n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        complete = round((i/event_data.shape[0])*100, 2)\n",
    "        print('%s%% complete' % complete)\n",
    "    \n",
    "    #create empty dictionary with keys\n",
    "    nes_dict = dict.fromkeys(all_nes)\n",
    "    \n",
    "    for ne in doc['nes_data'].keys():\n",
    "        nes_dict[ne] = doc['nes_data'].get(ne)\n",
    "    \n",
    "    row = list(nes_dict.values())\n",
    "    row = pd.Series(row, index=ne_cols)\n",
    "    row = pd.DataFrame(row).T\n",
    "    event_data_nes = event_data_nes.append(row, ignore_index=True)\n",
    "    \n",
    "event_data = pd.merge(event_data, event_data_nes, left_index=True, right_index=True)\n",
    "print('100%% complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#na as 0\n",
    "event_data.to_csv('%s_data_features.txt' % event_name, sep='\\t', encoding='utf-8', header=True, index=False, na_rep=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
